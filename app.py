"""
app.py - Flask Backend Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„ØµÙˆØªÙŠØ©
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ØªÙ… Ù†Ø³Ø® Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø¨Ø¯Ù‚Ø© Ù…Ù† Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£ØµÙ„ÙŠØ©
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import numpy as np
import librosa
from tensorflow import keras
import joblib
import os
import io
from werkzeug.utils import secure_filename

app = Flask(__name__)
CORS(app)  # Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù€ Android Ø¨Ø§Ù„ÙˆØµÙˆÙ„

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª - Ù…Ù†Ø³ÙˆØ®Ø© Ø¨Ø¯Ù‚Ø© Ù…Ù† config.py
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# PARAMÃˆTRES AUDIO
SAMPLE_RATE = 16000          # âš ï¸ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ù† Ø£ÙƒÙˆØ§Ø¯Ùƒ
DURATION = 6                 # âš ï¸ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ù† Ø£ÙƒÙˆØ§Ø¯Ùƒ
NORMALIZE_AUDIO = True

# PARAMÃˆTRES FEATURES
N_MELS = 128                 # âš ï¸ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ù† Ø£ÙƒÙˆØ§Ø¯Ùƒ
N_FFT = 1024                 # âš ï¸ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ù† Ø£ÙƒÙˆØ§Ø¯Ùƒ
HOP_LENGTH = 512             # âš ï¸ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ù† Ø£ÙƒÙˆØ§Ø¯Ùƒ
FMIN = 50                    # âš ï¸ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ù† Ø£ÙƒÙˆØ§Ø¯Ùƒ
FMAX = 8000                  # âš ï¸ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ù† Ø£ÙƒÙˆØ§Ø¯Ùƒ
N_MFCC = 13                  # âš ï¸ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ù† Ø£ÙƒÙˆØ§Ø¯Ùƒ
N_CHROMA = 12                # âš ï¸ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ù† Ø£ÙƒÙˆØ§Ø¯Ùƒ

# Shape attendu
EXPECTED_N_FEATURES = 153    # 128 + 13 + 12
EXPECTED_TIME_FRAMES = 186   # âš ï¸ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…Ù† Ø£ÙƒÙˆØ§Ø¯Ùƒ

# Classes de maladies
DISEASE_CLASSES = [
    'asthma_or_copd',
    'covid',
    'parkinson',
    'voice_disorder'
]

DISEASE_NAMES_FR = {
    'asthma_or_copd': 'Asthme/BPCO',
    'covid': 'COVID-19',
    'parkinson': 'Parkinson',
    'voice_disorder': 'Troubles de la voix'
}

DISEASE_NAMES_AR = {
    'asthma_or_copd': 'Ø§Ù„Ø±Ø¨Ùˆ/Ù…Ø±Ø¶ Ø§Ù„Ø§Ù†Ø³Ø¯Ø§Ø¯ Ø§Ù„Ø±Ø¦ÙˆÙŠ',
    'covid': 'ÙƒÙˆÙÙŠØ¯-19',
    'parkinson': 'Ø¨Ø§Ø±ÙƒÙ†Ø³ÙˆÙ†',
    'voice_disorder': 'Ø§Ø¶Ø·Ø±Ø§Ø¨Ø§Øª Ø§Ù„ØµÙˆØª'
}

DISEASE_ICONS = {
    'asthma_or_copd': 'ğŸ«',
    'covid': 'ğŸ¦ ',
    'parkinson': 'ğŸ§ ',
    'voice_disorder': 'ğŸ—£ï¸'
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù€ Scaler
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("ğŸ”„ Loading model and scaler...")
try:
    model = keras.models.load_model('unified_model_phase2.h5')
    scaler = joblib.load('scaler.pkl')
    print("âœ… Model and scaler loaded successfully!")
except Exception as e:
    print(f"âŒ Error loading model: {e}")
    raise

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„ÙˆØ¸Ø§Ø¦Ù - Ù…Ù†Ø³ÙˆØ®Ø© Ø¨Ø¯Ù‚Ø© Ù…Ù† utils.py
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def preprocess_audio(audio, target_length=None):
    """
    Ù…Ù†Ø³ÙˆØ®Ø© Ø¨Ø¯Ù‚Ø© 100% Ù…Ù† utils.py
    """
    if target_length is None:
        target_length = SAMPLE_RATE * DURATION
    
    current_length = len(audio)
    
    if current_length < target_length:
        # Padding: rÃ©pÃ©ter le signal
        n_repeats = int(np.ceil(target_length / current_length))
        audio = np.tile(audio, n_repeats)[:target_length]
    elif current_length > target_length:
        # Truncation: prendre le centre
        start = (current_length - target_length) // 2
        audio = audio[start:start + target_length]
    
    assert len(audio) == target_length, "Erreur prÃ©traitement audio"
    return audio


def extract_features_phase1(audio):
    """
    Ù…Ù†Ø³ÙˆØ®Ø© Ø¨Ø¯Ù‚Ø© 100% Ù…Ù† utils.py
    Extrait EXACTEMENT les mÃªmes features que Phase 1
    """
    features_list = []
    
    # 1. Mel Spectrogram (128 features)
    mel_spec = librosa.feature.melspectrogram(
        y=audio,
        sr=SAMPLE_RATE,
        n_mels=N_MELS,
        n_fft=N_FFT,
        hop_length=HOP_LENGTH,
        fmin=FMIN,
        fmax=FMAX
    )
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
    features_list.append(mel_spec_db)
    
    # 2. MFCC (13 features)
    mfcc = librosa.feature.mfcc(
        y=audio,
        sr=SAMPLE_RATE,
        n_mfcc=N_MFCC,
        n_fft=N_FFT,
        hop_length=HOP_LENGTH
    )
    features_list.append(mfcc)
    
    # 3. Chroma (12 features)
    chroma = librosa.feature.chroma_stft(
        y=audio,
        sr=SAMPLE_RATE,
        n_fft=N_FFT,
        hop_length=HOP_LENGTH,
        n_chroma=N_CHROMA
    )
    features_list.append(chroma)
    
    # Combiner verticalement
    features = np.vstack(features_list)
    
    # VÃ©rification critique du shape
    expected_shape = (EXPECTED_N_FEATURES, EXPECTED_TIME_FRAMES)
    
    # Si time dimension diffÃ©rente, forcer Ã  186 frames
    if features.shape[1] != EXPECTED_TIME_FRAMES:
        if features.shape[1] < EXPECTED_TIME_FRAMES:
            # Pad with zeros
            pad_width = EXPECTED_TIME_FRAMES - features.shape[1]
            features = np.pad(features, ((0, 0), (0, pad_width)), mode='constant')
        else:
            # Truncate
            features = features[:, :EXPECTED_TIME_FRAMES]
    
    # VÃ©rification finale
    assert features.shape == expected_shape, \
        f"âŒ Shape invalide! Attendu {expected_shape}, reÃ§u {features.shape}"
    
    return features


def load_audio_file(audio_bytes):
    """
    ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ù† bytes (Ù…Ù† Android)
    Ù…Ù†Ø³ÙˆØ®Ø© Ù…Ù† utils.py Ù…Ø¹ ØªØ¹Ø¯ÙŠÙ„ Ù„Ù„Ù€ bytes
    """
    try:
        # ØªØ­Ù…ÙŠÙ„ Ù…Ù† bytes
        audio, sr = librosa.load(
            io.BytesIO(audio_bytes),
            sr=SAMPLE_RATE,
            mono=True,
            duration=None
        )
        
        if len(audio) == 0:
            return None
        
        # Normaliser
        if NORMALIZE_AUDIO:
            audio = librosa.util.normalize(audio)
        
        # PrÃ©traiter pour obtenir longueur exacte
        audio = preprocess_audio(audio)
        
        return audio
        
    except Exception as e:
        print(f"âš ï¸ Erreur chargement audio: {e}")
        return None


def predict_audio(audio):
    """
    Ù…Ù†Ø³ÙˆØ®Ø© Ù…Ù† 09_unified_prediction.py
    """
    try:
        # 1. Extraction features
        features = extract_features_phase1(audio)
        
        # 2. Normalisation avec scaler
        features_flat = features.flatten().reshape(1, -1)
        features_scaled = scaler.transform(features_flat)
        
        # 3. Reshape pour le modÃ¨le
        features_final = features_scaled.reshape(
            1, EXPECTED_N_FEATURES, EXPECTED_TIME_FRAMES, 1
        )
        
        # 4. PrÃ©diction
        predictions = model.predict(features_final, verbose=0)
        
        # 5. Extraction rÃ©sultats
        if isinstance(predictions, dict):
            binary_key = [k for k in predictions.keys() if k != 'disease_output'][0]
            binary_pred = predictions[binary_key]
            disease_pred = predictions['disease_output']
        else:
            binary_pred, disease_pred = predictions
        
        # 6. Phase 1: Healthy vs Sick
        binary_prob = float(binary_pred[0][0])
        is_healthy = binary_prob < 0.5
        binary_confidence = float((1 - binary_prob) if is_healthy else binary_prob)
        
        if is_healthy:
            return {
                'success': True,
                'healthy': True,
                'binary_confidence': binary_confidence,
                'disease': None,
                'disease_name_fr': None,
                'disease_name_ar': None,
                'disease_confidence': None,
                'icon': 'âœ…'
            }
        
        # 7. Phase 2: Disease classification
        disease_probs = disease_pred[0]
        disease_idx = int(np.argmax(disease_probs))
        disease_name = DISEASE_CLASSES[disease_idx]
        disease_confidence = float(disease_probs[disease_idx])
        
        return {
            'success': True,
            'healthy': False,
            'binary_confidence': binary_confidence,
            'disease': disease_name,
            'disease_name_fr': DISEASE_NAMES_FR[disease_name],
            'disease_name_ar': DISEASE_NAMES_AR[disease_name],
            'disease_confidence': disease_confidence,
            'icon': DISEASE_ICONS[disease_name],
            'all_probabilities': {
                DISEASE_CLASSES[i]: float(disease_probs[i])
                for i in range(len(DISEASE_CLASSES))
            }
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API Endpoints
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/', methods=['GET'])
def home():
    """ØµÙØ­Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©"""
    return jsonify({
        'message': 'Disease Detection API',
        'status': 'running',
        'version': '1.0',
        'endpoints': {
            '/predict': 'POST - Upload audio file for prediction',
            '/health': 'GET - Check API health'
        }
    })


@app.route('/health', methods=['GET'])
def health():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù€ API"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': model is not None,
        'scaler_loaded': scaler is not None
    })


@app.route('/predict', methods=['POST'])
def predict():
    """
    Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„ØµÙˆØª Ù…Ù† Android ÙˆØ§Ù„ØªÙ†Ø¨Ø¤
    """
    try:
        # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù
        if 'audio' not in request.files:
            return jsonify({
                'success': False,
                'error': 'No audio file provided'
            }), 400
        
        audio_file = request.files['audio']
        
        if audio_file.filename == '':
            return jsonify({
                'success': False,
                'error': 'Empty filename'
            }), 400
        
        # 2. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
        audio_bytes = audio_file.read()
        
        # 3. ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
        audio = load_audio_file(audio_bytes)
        
        if audio is None:
            return jsonify({
                'success': False,
                'error': 'Failed to load audio'
            }), 400
        
        # 4. Ø§Ù„ØªÙ†Ø¨Ø¤
        result = predict_audio(audio)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
